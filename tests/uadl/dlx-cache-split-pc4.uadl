//
// A basic model with split L1 (instruction and data) cache.  This version adds
// an extra pipeline stage, creating more delay between memory access requests
// and the actual read and write.  This checks to make sure that a store-next
// request doesn't have a problem if its corresponding store-buffer entry hasn't
// yet been added.
//
define (core P) {

  allow_unimpl_instrs = true;

  define (resources) {

    // instruction buffer (fetch stage)
    define (fetchunit Fetcher) {
      fetch_memory = L1i;
      entries = 22;
      entry_size = 2;
      fetch_size = (8,4);
    }

    // pipeline stages
    define (pipestage=(mID, mEX0, mEX1, mMM, mWB)) {}

    // memory system
    define (cache L1i) {
      next_level_memory = Mem.I;
      write_mode = WriteBack;
      data_width = 64;
      max_requests = 1;
      taken_to_write_latency = 2;
      preemptive = false;
      write_to_next_level_request_latency = 1;
      read_hit_latency = 0;
      streaming_linefill = true; 
      // Number of cycles during which a cache linefill cannot be performed
      // after a cache linefill is initiated.
      linefill_lock_cycle = 1; 
      // The lock is delayed by an extra cycle to model the maintenance cycle
      // when the linefill is dumped into the cache array
      linefill_lock_holdoff_cycle = 2;
      linefill_lazy_writeback = true; 
      linefill_lock_on_valid = true;
      linefill_read_latency = 0;
      // If linefill is accompanied by eviction, the additional cycles during
      // which the cache cannot do a lookup
      evict_lock_cycle = 1;
    }

    define (cache L1d) {
      custom = (MyCache,"MyCache.h");
      next_level_memory = Mem.D;
      write_mode = WriteThrough;
      data_width = 64;
      // Two transactions may be pipelined within the cache.
      max_requests = 2;
      store_buffer_size = 4;
      taken_to_write_latency = 2;
      preemptive = false;
      write_to_next_level_request_latency = 1;
      read_hit_latency = 0;    
      streaming_linefill = true; 
      // Number of cycles during which a cache linefill cannot be performed
      // after a cache linefill is initiated.
      linefill_lock_cycle = 0; 
      // The lock is delayed by an extra cycle to model the maintenance cycle
      // when the linefill is dumped into the cache array
      linefill_lock_holdoff_cycle = 2;
      linefill_lazy_writeback = false; 
      linefill_lock_on_valid = true;
      linefill_read_latency = 0;
      // Note: This uses a custom cache where block_on_critical_word is set
      // directly.  So, we're purposefully not setting it here.
      //block_on_critical_word = serialized;
      // If linefill is accompanied by eviction, the additional cycles during
      // which the cache cannot do a lookup
      evict_lock_cycle = 1;
      consecutive_linefills = true;
    }

    define (memory Mem) {
      data_width = 64;
      max_requests = 4;

      define(port I) {
        type = instr;
        addr_bandwidth = 1;
        data_bandwidth = 1;
        read_latency = 2;
        max_requests = 2;
        allow_bus_wait = true;
      }
      define(port D) {
        // Combined bandwidth, so that requests and data use up the same
        // bandwidth.
        type = data;
        read_latency = 2;
        write_latency = 2;
        max_requests = 2;
        allow_bus_wait = true;
      }	
    }
  }

  mem_access = func (UadlMemAccess ma) { 
    // If the address falls within the guarded region, set the access as
    // serialized for memory (second level).
    if (ma.ea() > 0x10000 && ma.ea() < 0x1ffff) {
      ma.set_serialized_level(1);
    }
  };

  define (machine normal) {
    init_state = S_INIT;
    states = ( S_ID, S_IDp, S_EX0, S_EX0p, S_EX1, S_EX1p, S_MM, S_MMp, S_WB, S_WBp,
               S_IDe, S_EX0e, S_EX1e, S_MMe, S_WBe );

    define (mapping) {
      mID = (S_ID,S_IDp);
      mEX0 = (S_EX0,S_EX0p);
      mEX1 = (S_EX1,S_EX1p);
      mMM = (S_MM,S_MMp);
      mWB = (S_WB,S_WBp);
    };

    define (exception_mapping) {
      S_IDe = (S_ID,S_IDp);
      S_EX0e = (S_EX0,S_EX0p);
      S_EX1e = (S_EX1,S_EX1p);
      S_MMe = (S_MM,S_MMp);
      S_WBe = (S_WB,S_WBp);
    }

  }

  define (instr_class sfx) {
    instructions = ( "addic.", addi, addis, ori, "andi.", 
                     add, or, rlwinm, mullw,
                     cmpi, cmp, 
                     mtspr, mfspr, srw, halt );

    machine = normal;

    define (operands) {
      Src = sources;
      Trg = targets;
    }

    action = {
		S_INIT: { 
			change_state(S_ID); 
		};
		S_ID: if (Src.can_read() && Trg.can_write()) {
				Src.read();
				Trg.allocate();
				change_state(S_IDp);
			}
    S_IDp:  { change_state(S_EX0); }
		S_EX0: {
			exec();
			change_state(S_EX0p);
		}
    S_EX0p:  { change_state(S_EX1); }
		S_EX1: { 
			change_state(S_WB); 
		}
		S_MM: { 
			change_state(S_WB); 
		}
		S_WB: {
      write_ops();
      change_state(S_INIT);
    }
    };
  };

  // An example of a user-defined declaration in the uadl file.
  enum ExampleDecl { tFoo, tBar };

  bool check_cache(ExampleDecl x,InstrType &instr,Logger *logger)
  {
    return L1d.example_new_transaction(thisCore(),instr,logger,10) && 
      L1d.can_request_read(thisCore(),instr,logger) && L1d.linefill_not_blocked(thisCore(),instr,logger);
  }

 define (instr_class load) {
    instructions = ( lbz, lhz, lwz, lwzu, lwzx );

    machine = normal;
    
    define (operands) {
      Src = sources;
      Trg = targets;
      Imm = field(D);
    };

    allow_missing_operands = true;

    action = {
		S_INIT: { 
			change_state(S_ID); 
		};
		S_ID: if (Src.can_read() && Trg.can_write() && mEX0.has_space()) {
        Src.read();
				Trg.allocate();
				change_state(S_IDp);
			}
    S_IDp: if (check_cache(tFoo,thisInstr(),logger) && mEX0.has_space()) {
        exec();
        L1d.send_read_request();
        change_state(S_EX0);
      }
    S_EX0: if (mEX1.has_space()) {
        change_state(S_EX0p);
      }
    S_EX0p:  { change_state(S_EX1); }
    S_EX1: { change_state(S_MM); };
		S_MM: if (L1d.can_read()) { 
        exec_and_read(L1d);
        change_state(S_MMp);
      }
    S_MMp: if (exec_done() && mWB.has_space()) {
        change_state(S_WB);
      }
      else if (L1d.can_request_read()) {
        L1d.send_read_request();
        change_state(S_MM);
      }
		S_WB: {
      write_ops();
      change_state(S_WBp);
    }
		S_WBp:{
			change_state(S_INIT);
		}
    };
  }

  define (instr_class lmw) {
    instructions = ( lmw );

    machine = normal;
    
    define (operands) {
      Src = sources;
      Trg = targets;
    };

    action = {
		S_INIT: { 
			change_state(S_ID); 
		};
		S_ID: if (Src.can_read() && Trg.can_write()) {
        Src.read();
				Trg.allocate();
				change_state(S_IDp);
			}
    S_IDp:  { change_state(S_EX0); }
    S_EX0: if (mEX1.has_space() && L1d.can_request_read()) {
        // Calc ea.
        exec();
        L1d.send_read_request(8);
        next_req_mem();
        change_state(S_EX1);
      }
    S_EX1: { change_state(S_MM); };
		S_MM: if (L1d.can_read()) { 
        exec_and_read(L1d,2);
        change_state(S_MMp);
      }
    // "edge" action:  If we're done executing, then move to writeback, else stay at MM.
    S_MMp: if (exec_done() && mWB.has_space()) {
        change_state(S_WB);
      }
      else if (L1d.can_request_read()) {
        L1d.send_read_request(8);
        next_req_mem();
        change_state(S_MM);
      }
		// No need for a space-check, since S_WBp maps to the same stage.
		S_WB: {
      write_ops();
      change_state(S_WBp);
    }
		S_WBp:{
			change_state(S_INIT);
		}

    };
 }

 define (instr_class store) {
    instructions = (stb, sth, sthx, stw, stwu, stwx);

    machine = normal;
    
    define (operands) {
      Src = sources;
      Trg = targets;
    };

    allow_missing_operands = true;

    action = {
		S_INIT: { 
			change_state(S_ID); 
		};
    // TBD:  send_read_request_queue_inquire(L1d);
		S_ID: if (Src.can_read() && Trg.can_write()) {
				Src.read();
        Trg.allocate();
				change_state(S_IDp);
			}
    S_IDp: if (L1d.can_accept_write_requests() && mEX0.has_space()) {
        // If we're serialized, then store this fact using the latency counter.
        // Clear the flag so that it doesn't influence it further.
        set_latency(is_serialized());
        clr_serialized(0x3);
        change_state(S_EX0);
      }
    S_EX0: if (mEX1.has_space() && L1d.can_request_write()) {
        // Calc ea.
        exec();
        L1d.send_write_request();
        change_state(S_EX1);
      }
    S_EX1: { change_state(S_MM); };
		S_MM: if (L1d.can_write()) { 
        exec_and_write(L1d);
        change_state(S_MMp);
      }
    // "edge" action: If we're done executing, then move to writeback, else stay
    // at MM.  Check the latency counter- if it's non-zero, it means we're
    // serialized, in which case we can't finish until the store buffer is done.
    S_MMp: if (exec_done() && mWB.has_space()) {
        if (!latency() || L1d.store_buf_done()) {
          change_state(S_WB);
        }
      }
      else if (L1d.can_request_write()) {
        L1d.send_write_request();
        change_state(S_MM);
      }
		// No need for a space-check, since S_WBp maps to the same stage.
		S_WB: {
      write_ops();
      change_state(S_WBp);
    }
		S_WBp: {
      change_state(S_INIT);
    }
    };
  }

 define (instr_class stmw) {
    instructions = ( stmw );

    machine = normal;
    
    // Ugly, but this makes sure that we can list an operand multiple times in
    // order to include multiple resources.  Could be simplified by having a
    // single source operand with "sources" as a value.
    define (operands) {
      Src = sources;
    };

    action = {
		S_INIT: { 
			change_state(S_ID); 
		};
		S_ID: if (Src.can_read()) {
				Src.read();
				change_state(S_IDp);
			}
    S_IDp:  { change_state(S_EX0); }
    S_EX0: if (mEX1.has_space() && L1d.can_request_write()) {
        // Calc ea.
        exec();
        if (is_misaligned(0x7)) {
          L1d.send_write_request();
        } else {
          L1d.send_write_request(8);
          next_req_mem();
        }
        change_state(S_EX1);
      }
    S_EX1: { change_state(S_MM); };
		S_MM: if (L1d.can_write()) { 
        // Do 64-bit writes, unless our request is odd in size, in which case
        // we'll have a 4-byte write at the end.
        if (is_misaligned(0x7)) {
          exec_and_write(L1d);
        } else {
          exec_and_write(L1d,2,4);
        }
        change_state(S_MMp);
      }
    // "edge" action:  If we're done executing, then move to writeback, else stay at MM.
    S_MMp: if (exec_done() && mWB.has_space()) {
        change_state(S_WB);
      }
      else if (L1d.can_request_write()) {
        L1d.send_write_request(8);
        next_req_mem();
        change_state(S_MM);
      }
		// No need for a space-check, since S_WBp maps to the same stage.
		S_WB: {
      change_state(S_WBp);
    }
		S_WBp: {
      change_state(S_INIT);
    }

    };
  }

 define (instr_class branch) {
   instructions = ( bc, b, bl, bclr );
   
   machine = normal;

   allow_missing_operands = true;
   
   action = {
   S_INIT :{
     change_state(S_ID);
   };
   S_ID: if (can_read_ops() && can_write_ops()) {
       read_ops();
       allocate_ops();
       exec();
       write_ops();
       if (branch_taken()) {
         taken_flush();
       }
       change_state(S_IDp);
     }
   S_IDp:  { change_state(S_EX0); }
   S_EX0: {
       change_state(S_EX1);
     }
   S_EX1: {
       change_state(S_MM);
     }
   S_MM: {
     change_state(S_WB);
   }
   S_WB: {
     change_state(S_INIT);
   }
   };
 }

 bool l1d_can_request_cmd_1(InstrType &instr,Logger *logger)
 {
   return L1d.can_request_cmd(thisCore(),instr,logger);
 }

 bool l1d_can_request_cmd_2(InstrType &instr,Logger *logger)
 {
   return L1d.can_request_cmd(thisCore(),instr,logger);
 }

 define (instr_class cache) {
    instructions = ( dcbt, dcbf, dcbst, dcbz, dcbi, dcba );

    machine = normal;
    
    define (operands) {
      Src = sources;
    };

    // Not really useful in this situation, since we just have one cache, but
    // this is here to check code generation.
    define (functions) {
      can_request_cmd = l1d_can_request_cmd_1;
    }

    define (instr=(dcbt,dcbf)) {
      define (functions) {
        can_request_cmd = l1d_can_request_cmd_2;
      }
    }

    action = {
		S_INIT: if (mID.empty() && mEX0.empty() && mMM.empty() && mWB.empty()) { 
			change_state(S_ID); 
		};
		S_ID: if (Src.can_read() && mEX0.has_space()) {
        Src.read();
				change_state(S_EX0);
			}
    S_EX0: if (mEX1.has_space() && can_request_cmd(thisInstr(),logger)) {
        // Calc ea.
        exec();
        L1d.send_cmd();
        exec();
        change_state(S_EX0p);
      }
    S_EX0p: if (exec_done() && mEX1.has_space()) {
        change_state(S_MM);
      }
      else if (L1d.can_request_cmd()) {
        // dcbf consists of a flush and an invalidate.
        L1d.send_cmd();
        exec();
        if (mEX1.has_space()) {
          change_state(S_EX1);
        }
      }
    S_EX1: { change_state(S_MM); };
    S_MM: {
      change_state(S_WB);
    }
		S_WB: {
      change_state(S_INIT);
    }
    };
  }

}
